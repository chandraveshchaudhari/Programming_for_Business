{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb1640d-9f8e-4c33-9d80-2335a13a0080",
   "metadata": {},
   "source": [
    "# Advanced DL: ResNets, RNNs\n",
    "\n",
    "\t• Residual Learning and Skip Connections\n",
    "\t• Vanishing Gradients and RNNs\n",
    "\t• Gating Mechanisms in LSTM \n",
    "\t• Python: Custom RNN Implementation\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here’s your complete Advanced Deep Learning module on ResNets and RNNs, including theory and a basic Python implementation of a custom RNN.\n",
    "\n",
    "⸻\n",
    "\n",
    "Advanced DL: ResNets, RNNs\n",
    "\n",
    "⸻\n",
    "\n",
    "1. Residual Learning and Skip Connections (ResNets)\n",
    "\n",
    "Problem: As deep networks grow, training error increases due to vanishing/exploding gradients.\n",
    "\n",
    "Solution: Residual blocks with skip connections:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\t•\t$\\mathcal{F}(\\mathbf{x})$: Residual mapping (e.g., two conv layers).\n",
    "\t•\t$\\mathbf{x}$: Identity shortcut.\n",
    "\n",
    "Benefits:\n",
    "\t•\tEasier to optimize.\n",
    "\t•\tAllows very deep networks (e.g., ResNet-50, ResNet-101).\n",
    "\t•\tGradient flows directly through the skip path.\n",
    "\n",
    "⸻\n",
    "\n",
    "2. Vanishing Gradients and RNNs\n",
    "\n",
    "Recurrent Neural Networks (RNNs) handle sequential data:\n",
    "\n",
    "$$\n",
    "h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b)\n",
    "$$\n",
    "\n",
    "Vanishing Gradient Problem:\n",
    "\t•\tGradients shrink as they propagate back through time.\n",
    "\t•\tMakes learning long-term dependencies difficult.\n",
    "\n",
    "⸻\n",
    "\n",
    "3. Gating Mechanisms in LSTM\n",
    "\n",
    "LSTM (Long Short-Term Memory) units solve vanishing gradient with gates:\n",
    "\t•\tForget Gate: What to forget.\n",
    "\t•\tInput Gate: What new info to add.\n",
    "\t•\tOutput Gate: What to output.\n",
    "\n",
    "Core equations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_t &= \\sigma(W_f [h_{t-1}, x_t] + b_f) \\\n",
    "i_t &= \\sigma(W_i [h_{t-1}, x_t] + b_i) \\\n",
    "\\tilde{C}t &= \\tanh(W_C [h{t-1}, x_t] + b_C) \\\n",
    "C_t &= f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}t \\\n",
    "o_t &= \\sigma(W_o [h{t-1}, x_t] + b_o) \\\n",
    "h_t &= o_t \\odot \\tanh(C_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "⸻\n",
    "\n",
    "4. Python: Custom RNN Implementation (from scratch)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, seq_len):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.Wxh = np.random.randn(input_size, hidden_size) * 0.1\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.Why = np.random.randn(hidden_size, output_size) * 0.1\n",
    "        self.bh = np.zeros((1, hidden_size))\n",
    "        self.by = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.h = np.zeros((X.shape[0], self.hidden_size))\n",
    "        self.hs = []\n",
    "\n",
    "        for t in range(self.seq_len):\n",
    "            x_t = X[:, t, :]\n",
    "            self.h = np.tanh(x_t @ self.Wxh + self.h @ self.Whh + self.bh)\n",
    "            self.hs.append(self.h.copy())\n",
    "\n",
    "        y = self.h @ self.Why + self.by\n",
    "        return y\n",
    "\n",
    "# Example: Predict sum of sequence\n",
    "np.random.seed(0)\n",
    "seq_len = 5\n",
    "X = np.random.rand(100, seq_len, 1)\n",
    "y = np.sum(X, axis=1)\n",
    "\n",
    "rnn = SimpleRNN(input_size=1, hidden_size=10, output_size=1, seq_len=seq_len)\n",
    "y_pred = rnn.forward(X)\n",
    "\n",
    "print(\"Predicted shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "Would you like to follow up with custom LSTM implementation, or build a ResNet block in PyTorch next?"
   ],
   "id": "d87e1a206bb9d812"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
