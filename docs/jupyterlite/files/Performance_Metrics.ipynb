{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Performance Metrics",
   "id": "575329dfe48eec9b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f027157e-95bb-462d-9c79-e6260787522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    # True Positives, False Positives, True Negatives, False Negatives\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # Recall\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384a43c-145b-4467-97e7-ab892bf9fba3",
   "metadata": {},
   "source": [
    "\n",
    "## Function: `calculate_metrics(y_true, y_pred)`\n",
    "\n",
    "This function calculates common **classification evaluation metrics**, assuming a **binary classification problem**, where:\n",
    "\n",
    "* \\$ y\\_{\\text{true}} \\$ = Array of actual class labels (0 or 1)\n",
    "* \\$ y\\_{\\text{pred}} \\$ = Array of predicted class labels (0 or 1)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Confusion Matrix Components**\n",
    "\n",
    "The following are calculated using logical conditions:\n",
    "\n",
    "* **True Positives (TP)**: Predicted = 1, Actual = 1\n",
    "\n",
    "  $$\n",
    "  TP = \\sum{(y_{\\text{true}} = 1) \\land (y_{\\text{pred}} = 1)}\n",
    "  $$\n",
    "\n",
    "* **False Positives (FP)**: Predicted = 1, Actual = 0\n",
    "\n",
    "  $$\n",
    "  FP = \\sum{(y_{\\text{true}} = 0) \\land (y_{\\text{pred}} = 1)}\n",
    "  $$\n",
    "\n",
    "* **True Negatives (TN)**: Predicted = 0, Actual = 0\n",
    "\n",
    "  $$\n",
    "  TN = \\sum{(y_{\\text{true}} = 0) \\land (y_{\\text{pred}} = 0)}\n",
    "  $$\n",
    "\n",
    "* **False Negatives (FN)**: Predicted = 0, Actual = 1\n",
    "\n",
    "  $$\n",
    "  FN = \\sum{(y_{\\text{true}} = 1) \\land (y_{\\text{pred}} = 0)}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "###  **Step 2: Accuracy**\n",
    "\n",
    "**Proportion of correct predictions (both 0's and 1's):**\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "###  **Step 3: Precision**\n",
    "\n",
    "**Out of all predicted positive cases, how many were correct:**\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "If denominator is zero (to avoid division by zero), precision is set to 0.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Step 4: Recall (Sensitivity or True Positive Rate)**\n",
    "\n",
    "**Out of all actual positive cases, how many were correctly predicted:**\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "###  **Step 5: F1 Score**\n",
    "\n",
    "**Harmonic mean of Precision and Recall:**\n",
    "It balances Precision and Recall, useful when you care about both.\n",
    "\n",
    "$$\n",
    "F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "If both precision and recall are zero, F1 is set to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99739fd-45ff-498e-853d-29522ba418fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
