{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1fb890d-125c-4755-ab67-2fbb326bb74f",
   "metadata": {
    "panel-layout": {
     "height": 68.28125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Common Math Symbols and Notations in Machine Learning\n",
    "\n",
    "## 1. General Notations\n",
    "- **Scalars**: Lowercase letters ($x$, $y$, $\\theta$)\n",
    "- **Vectors**: Bold lowercase letters ($\\mathbf{x}$, $\\mathbf{w}$)\n",
    "- **Matrices**: Bold uppercase letters ($\\mathbf{X}$, $\\mathbf{W}$)\n",
    "- **Tensors**: Calligraphic letters ($\\mathcal{T}$)\n",
    "- **Sets**: Uppercase letters ($\\mathcal{D}$ for dataset)\n",
    "- **Indexing**: $x_i$ (i-th element of vector $\\mathbf{x}$), $\\mathbf{W}_{i,j}$ (i,j-th element of matrix $\\mathbf{W}$)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Loss Functions & Errors\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $\\mathcal{L}$ | General loss function |\n",
    "| $J(\\theta)$ | Cost function |\n",
    "| $\\ell(y, \\hat{y})$ | Loss between true $y$ and predicted $\\hat{y}$ |\n",
    "| $\\text{MSE}$ | Mean Squared Error $\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2$ |\n",
    "| $\\text{CE}$ | Cross-Entropy Loss $-\\sum y_i \\log(\\hat{y}_i)$ |\n",
    "| $\\epsilon$ | General error term |\n",
    "| $E$ | Expected value ($\\mathbb{E}[X]$) |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Optimization & Gradients\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $\\nabla_\\theta J$ | Gradient of $J$ w.r.t. $\\theta$ |\n",
    "| $\\partial J / \\partial \\theta$ | Partial derivative |\n",
    "| $\\eta$ | Learning rate |\n",
    "| $\\theta_{t+1} = \\theta_t - \\eta \\nabla J(\\theta_t)$ | Gradient descent update |\n",
    "| $\\alpha$ | Momentum coefficient |\n",
    "| $\\beta_1, \\beta_2$ | Adam hyperparameters |\n",
    "| $\\lambda$ | Regularization coefficient |\n",
    "| $\\arg \\min_\\theta J(\\theta)$ | Optimal $\\theta$ minimizing $J$ |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Probability & Statistics\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $p(x)$ | Probability density/mass function |\n",
    "| $P(y \\mid x)$ | Conditional probability |\n",
    "| $\\mathbb{E}[X]$ | Expectation |\n",
    "| $\\text{Var}(X)$ | Variance |\n",
    "| $\\mathcal{N}(\\mu, \\sigma^2)$ | Gaussian distribution |\n",
    "| $\\sim$ | \"Distributed as\" ($x \\sim \\mathcal{N}(0,1)$) |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Linear Algebra\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $\\mathbf{X}^T$ | Matrix transpose |\n",
    "| $\\mathbf{W}^\\dagger$ | Pseudoinverse |\n",
    "| $\\|\\mathbf{x}\\|_2$ | L2 norm |\n",
    "| $\\|\\mathbf{x}\\|_1$ | L1 norm |\n",
    "| $\\mathbf{I}$ | Identity matrix |\n",
    "| $\\text{tr}(\\mathbf{A})$ | Trace |\n",
    "| $\\text{det}(\\mathbf{A})$ | Determinant |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Neural Networks\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $\\sigma(z)$ | Activation function |\n",
    "| $\\text{ReLU}(z)$ | $\\max(0, z)$ |\n",
    "| $\\mathbf{h}^{(l)}$ | Hidden layer $l$ |\n",
    "| $\\mathbf{W}^{(l)}$ | Weight matrix |\n",
    "| $\\mathbf{b}^{(l)}$ | Bias vector |\n",
    "| $\\odot$ | Hadamard product |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Special Notations\n",
    "| Symbol       | Meaning |\n",
    "|--------------|---------|\n",
    "| $\\mathbb{1}$ | Indicator function |\n",
    "| $\\delta_{ij}$ | Kronecker delta |\n",
    "| $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$ | Dot product |\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Gradient Descent Update\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta J(\\theta_t)\n",
    "$$\n",
    "where:\n",
    "- $\\theta$ = model parameters\n",
    "- $\\eta$ = learning rate\n",
    "- $\\nabla_\\theta J$ = gradient of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbba55e-d78d-48ab-8b04-c10ed1ade9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f5625-134c-41a4-b606-c0323e0617fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca62c8b-80b7-49c9-aa85-44632784611b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baf37b-05ce-49a9-b6c5-bcec7ab811d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "f1fb890d-125c-4755-ab67-2fbb326bb74f"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
